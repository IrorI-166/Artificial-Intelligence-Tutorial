# 単回帰分析について
単回帰分析とは、目的変数に対する説明変数が一つの場合の回帰分析のこと。

## ソースコードの詳細解説
#### 42~43行目
```py
# 線形回帰モデルの作成と学習
model = LinearRegression()
model.fit(X_train.reshape(-1, 1), y_train)
```
これは、scikit-learnで実装した線形回帰モデルの学習プロセスである。
`model = LinearRegression()`は、a, bをスカラーとしたときの`y = a * x + b`を作成し、model変数に代入している。
この時、xとyにはテストデータが代入されるので、数学的には、aとbの2変数関数を考えることになる。

`model.fit(X_train.reshape(-1, 1), y_train)`は、y = a * x + bにおいてxにX_train、yにY_trainの値を代入している。
`X_train.reshape(-1, 1)`でX_trainの形状を(n, 1)行列に変換している。ここで n はデータの個数を表す。この変換は、X_train を縦ベクトル（列ベクトル）に変換するためのもの。

ChatGPT:
```
`X_train` を縦ベクトル（列ベクトル）に変換する理由は、線形回帰モデルが通常、説明変数を列ベクトルとして受け取るためです。

線形回帰モデルでは、説明変数 `X_train` を入力として受け取ります。通常、説明変数は2次元のデータであり、各データポイントが行として表されます。しかし、`X_train` は `(n,)` の形状を持つ1次元の配列（ベクトル）である場合があります。

`X_train.reshape(-1, 1)` は、このような1次元の配列を `(n, 1)` の形状を持つ2次元の配列（縦ベクトル）に変換します。こうすることで、モデルは入力データを正しく解釈し、適切な予測を行うことができます。

線形回帰モデルにおいては、入力データとして行ベクトル（横ベクトル）や1次元の配列を使用することも一般的ですが、多くのライブラリやフレームワークでは列ベクトルの形式を前提としています。そのため、`X_train.reshape(-1, 1)` のような変換が必要になる場合があります。
```

したがって、`model.fit(X_train.reshape(-1, 1), y_train)`が実行しているプロセスは以下の通りになる。
```
1.　(n, 1)行列のX_trainとY_trainをそれぞれ、y = a * x + bにおけるxとyに代入
2.　行列演算を行ってパラメータを仮決定
3.　最小二乗法で損失関数を求める
4.　損失関数が最小ならばパラメータを決定、最小でないならば2から再実行
```

scikit-learnの`fit`メソッド一つでこのプロセスがすべて自動的に実行されるというわけ。
52行目の`slope, intercept = np.polyfit(X_train.flatten(), y_train, 1)`はこれをnumpyで実装する場合のプログラムである。

#### 45~47行目
```py
# テストデータの予測
X_test = test_data_set[:, 0]  # 温度（説明変数）
y_test = test_data_set[:, 1]  # 売上金額（目的変数）
y_pred = model.predict(X_test.reshape(-1, 1))
```
上2行はデータをスライス処理で取り出している。
`predict`メソッドは、(n, 1)行列で与えられたテストデータを、パラメーターが決定されたモデルに入力し、行列演算を行ってその予測値を返す働きをする。
だから`Y_pred`の中身は以下の通りになる。ndarray型の(n, 1)行列である。
```txt
Y_pred: [ 414.47082597 1108.24721505  457.83185029  848.08106915  457.83185029
 1194.96926369  978.1641421   457.83185029  371.10980166  891.44209347
  674.63697188  544.55389893]
```

#### 57,58行目
```py
w = np.array([slope])
b = intercept
```
52行目で求めた`slope`と`intercept`を変数に代入している。
`slope`を行列に変換しているのは、後で使うときに便利なため。

#### 64行目
```py
predicted = np.dot(X_test.reshape(-1, 1), w) + b  # すべてのテストデータに対して予測を計算
```
